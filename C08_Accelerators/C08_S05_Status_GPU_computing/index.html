
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://klust.github.io/SupercomputersForStarters/C08_Accelerators/C08_S05_Status_GPU_computing/">
      
      
        <link rel="prev" href="../C08_S04_Programming_accelerators/">
      
      
        <link rel="next" href="../C08_S06_Further_reading/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.50">
    
    
      
        <title>Status of GPU computing - Supercomputers for Starters</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.a40c8224.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--demo:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 192h176V0h-16C71.6 0 0 71.6 0 160zm0 32v128c0 88.4 71.6 160 160 160h64c88.4 0 160-71.6 160-160V224H0m384-32v-32C384 71.6 312.4 0 224 0h-16v192z"/></svg>');--md-admonition-icon--exercise:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M78.6 5c-9.5-7.4-23-6.5-31.6 2L7 47c-8.5 8.5-9.4 22-2.1 31.6l80 104c4.5 5.9 11.6 9.4 19 9.4H158l109 109c-14.7 29-10 65.4 14.3 89.6l112 112c12.5 12.5 32.8 12.5 45.3 0l64-64c12.5-12.5 12.5-32.8 0-45.3l-112-112c-24.2-24.2-60.6-29-89.6-14.3L192 158v-54.1c0-7.5-3.5-14.5-9.4-19zM19.9 396.1C7.2 408.8 0 426.1 0 444.1 0 481.6 30.4 512 67.9 512c18 0 35.3-7.2 48-19.9l117.8-117.8c-7.8-20.9-9-43.6-3.6-65.1l-61.7-61.7zM512 144c0-10.5-1.1-20.7-3.2-30.5-2.4-11.2-16.1-14.1-24.2-6l-63.9 63.9c-3 3-7.1 4.7-11.3 4.7L352 176c-8.8 0-16-7.2-16-16v-57.4c0-4.2 1.7-8.3 4.7-11.3l63.9-63.9c8.1-8.1 5.2-21.8-6-24.2C388.7 1.1 378.5 0 368 0c-79.5 0-144 64.5-144 144v.8l85.3 85.3c36-9.1 75.8.5 104 28.7l15.7 15.7c49-23 83-72.8 83-130.5M56 432a24 24 0 1 1 48 0 24 24 0 1 1-48 0"/></svg>');--md-admonition-icon--remark:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 448c141.4 0 256-93.1 256-208S397.4 32 256 32 0 125.1 0 240c0 45.1 17.7 86.8 47.7 120.9-1.9 24.5-11.4 46.3-21.4 62.9-5.5 9.2-11.1 16.6-15.2 21.6-2.1 2.5-3.7 4.4-4.9 5.7-.6.6-1 1.1-1.3 1.4l-.3.3c-4.6 4.6-5.9 11.4-3.4 17.4s8.3 9.9 14.8 9.9c28.7 0 57.6-8.9 81.6-19.3 22.9-10 42.4-21.9 54.3-30.6 31.8 11.5 67 17.9 104.1 17.9zM128 208a32 32 0 1 1 0 64 32 32 0 1 1 0-64m128 0a32 32 0 1 1 0 64 32 32 0 1 1 0-64m96 32a32 32 0 1 1 64 0 32 32 0 1 1-64 0"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--audience:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M72 88a56 56 0 1 1 112 0 56 56 0 1 1-112 0m-8 157.7c-10 11.2-16 26.1-16 42.3s6 31.1 16 42.3v-84.7zm144.4-49.3C178.7 222.7 160 261.2 160 304c0 34.3 12 65.8 32 90.5V416c0 17.7-14.3 32-32 32H96c-17.7 0-32-14.3-32-32v-26.8C26.2 371.2 0 332.7 0 288c0-61.9 50.1-112 112-112h32c24 0 46.2 7.5 64.4 20.3zM448 416v-21.5c20-24.7 32-56.2 32-90.5 0-42.8-18.7-81.3-48.4-107.7C449.8 183.5 472 176 496 176h32c61.9 0 112 50.1 112 112 0 44.7-26.2 83.2-64 101.2V416c0 17.7-14.3 32-32 32h-64c-17.7 0-32-14.3-32-32m8-328a56 56 0 1 1 112 0 56 56 0 1 1-112 0m120 157.7v84.7c10-11.3 16-26.1 16-42.3s-6-31.1-16-42.3zM320 32a64 64 0 1 1 0 128 64 64 0 1 1 0-128m-80 272c0 16.2 6 31 16 42.3v-84.7c-10 11.3-16 26.1-16 42.3zm144-42.3v84.7c10-11.3 16-26.1 16-42.3s-6-31.1-16-42.3zm64 42.3c0 44.7-26.2 83.2-64 101.2V448c0 17.7-14.3 32-32 32h-64c-17.7 0-32-14.3-32-32v-42.8c-37.8-18-64-56.5-64-101.2 0-61.9 50.1-112 112-112h32c61.9 0 112 50.1 112 112"/></svg>');--md-admonition-icon--solution:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M234.7 42.7 197 56.8c-3 1.1-5 4-5 7.2s2 6.1 5 7.2l37.7 14.1 14.1 37.7c1.1 3 4 5 7.2 5s6.1-2 7.2-5l14.1-37.7L315 71.2c3-1.1 5-4 5-7.2s-2-6.1-5-7.2l-37.7-14.1L263.2 5c-1.1-3-4-5-7.2-5s-6.1 2-7.2 5zM46.1 395.4c-18.7 18.7-18.7 49.1 0 67.9l34.6 34.6c18.7 18.7 49.1 18.7 67.9 0l381.3-381.4c18.7-18.7 18.7-49.1 0-67.9l-34.6-34.5c-18.7-18.7-49.1-18.7-67.9 0zM484.6 82.6l-105 105-23.3-23.3 105-105zM7.5 117.2C3 118.9 0 123.2 0 128s3 9.1 7.5 10.8L64 160l21.2 56.5c1.7 4.5 6 7.5 10.8 7.5s9.1-3 10.8-7.5L128 160l56.5-21.2c4.5-1.7 7.5-6 7.5-10.8s-3-9.1-7.5-10.8L128 96l-21.2-56.5c-1.7-4.5-6-7.5-10.8-7.5s-9.1 3-10.8 7.5L64 96zm352 256c-4.5 1.7-7.5 6-7.5 10.8s3 9.1 7.5 10.8L416 416l21.2 56.5c1.7 4.5 6 7.5 10.8 7.5s9.1-3 10.8-7.5L480 416l56.5-21.2c4.5-1.7 7.5-6 7.5-10.8s-3-9.1-7.5-10.8L480 352l-21.2-56.5c-1.7-4.5-6-7.5-10.8-7.5s-9.1 3-10.8 7.5L416 352z"/></svg>');--md-admonition-icon--technical:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M160 96a96 96 0 1 1 192 0 96 96 0 1 1-192 0m80 152v264l-48.4-24.2c-20.9-10.4-43.5-17-66.8-19.3l-96-9.6C12.5 457.2 0 443.5 0 427V224c0-17.7 14.3-32 32-32h30.3c63.6 0 125.6 19.6 177.7 56m32 264V248c52.1-36.4 114.1-56 177.7-56H480c17.7 0 32 14.3 32 32v203c0 16.4-12.5 30.2-28.8 31.8l-96 9.6c-23.2 2.3-45.9 8.9-66.8 19.3z"/></svg>');--md-admonition-icon--intermediate:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 32c-8.1 0-16.1 1.4-23.7 4.1L15.8 137.4C6.3 140.9 0 149.9 0 160s6.3 19.1 15.8 22.6l57.9 20.9C57.3 229.3 48 259.8 48 291.9V320c0 28.4-10.8 57.7-22.3 80.8-6.5 13-13.9 25.8-22.5 37.6-3.2 4.3-4.1 9.9-2.3 15s6 8.9 11.2 10.2l64 16c4.2 1.1 8.7.3 12.4-2s6.3-6.1 7.1-10.4c8.6-42.8 4.3-81.2-2.1-108.7-3.2-14.2-7.5-28.7-13.5-42v-24.6c0-30.2 10.2-58.7 27.9-81.5 12.9-15.5 29.6-28 49.2-35.7l157-61.7c8.2-3.2 17.5.8 20.7 9s-.8 17.5-9 20.7l-157 61.7c-12.4 4.9-23.3 12.4-32.2 21.6l159.6 57.6c7.6 2.7 15.6 4.1 23.7 4.1s16.1-1.4 23.7-4.1l280.6-101c9.5-3.4 15.8-12.5 15.8-22.6s-6.3-19.1-15.8-22.6L343.7 36.1c-7.6-2.7-15.6-4.1-23.7-4.1M128 408c0 35.3 86 72 192 72s192-36.7 192-72l-15.3-145.4L354.5 314c-11.1 4-22.8 6-34.5 6s-23.5-2-34.5-6l-142.2-51.4z"/></svg>');--md-admonition-icon--advanced:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M219.3.5c3.1-.6 6.3-.6 9.4 0l200 40C439.9 42.7 448 52.6 448 64s-8.1 21.3-19.3 23.5L352 102.9V160c0 70.7-57.3 128-128 128S96 230.7 96 160v-57.1l-48-9.6v65.1l15.7 78.4c.9 4.7-.3 9.6-3.3 13.3S52.8 256 48 256H16c-4.8 0-9.3-2.1-12.4-5.9s-4.3-8.6-3.3-13.3L16 158.4V86.6C6.5 83.3 0 74.3 0 64c0-11.4 8.1-21.3 19.3-23.5zM111.9 327.7c10.5-3.4 21.8.4 29.4 8.5l71 75.5c6.3 6.7 17 6.7 23.3 0l71-75.5c7.6-8.1 18.9-11.9 29.4-8.5 65 20.9 112 81.7 112 153.6 0 17-13.8 30.7-30.7 30.7H30.7C13.8 512 0 498.2 0 481.3c0-71.9 47-132.7 111.9-153.6"/></svg>');--md-admonition-icon--vscentrum:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M48 0C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h96v-80c0-26.5 21.5-48 48-48s48 21.5 48 48v80h96c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm16 240c0-8.8 7.2-16 16-16h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16H80c-8.8 0-16-7.2-16-16zm112-16h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-32c-8.8 0-16-7.2-16-16v-32c0-8.8 7.2-16 16-16m80 16c0-8.8 7.2-16 16-16h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-32c-8.8 0-16-7.2-16-16zM80 96h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16H80c-8.8 0-16-7.2-16-16v-32c0-8.8 7.2-16 16-16m80 16c0-8.8 7.2-16 16-16h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-32c-8.8 0-16-7.2-16-16zm112-16h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-32c-8.8 0-16-7.2-16-16v-32c0-8.8 7.2-16 16-16M448 0c-17.7 0-32 14.3-32 32v480h64V192h144c8.8 0 16-7.2 16-16V48c0-8.8-7.2-16-16-16H480c0-17.7-14.3-32-32-32"/></svg>');--md-admonition-icon--nice-to-know:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M297.2 248.9c14.4-20.6 22.8-45.7 22.8-72.9 0-70.7-57.3-128-128-128S64 105.3 64 176c0 27.2 8.4 52.3 22.8 72.9 3.7 5.3 8.1 11.3 12.8 17.7 12.9 17.7 28.3 38.9 39.8 59.8 10.4 19 15.7 38.8 18.3 57.5l-48.7.1c-2.2-12-5.9-23.7-11.8-34.5-9.9-18-22.2-34.9-34.5-51.8-5.2-7.1-10.4-14.2-15.4-21.4C27.6 247.9 16 213.3 16 176 16 78.8 94.8 0 192 0s176 78.8 176 176c0 37.3-11.6 71.9-31.4 100.3-5 7.2-10.2 14.3-15.4 21.4-12.3 16.8-24.6 33.7-34.5 51.8-5.9 10.8-9.6 22.5-11.8 34.5h-48.6c2.6-18.7 7.9-38.6 18.3-57.5 11.5-20.9 26.9-42.1 39.8-59.8 4.7-6.4 9-12.4 12.7-17.7zM192 128c-26.5 0-48 21.5-48 48 0 8.8-7.2 16-16 16s-16-7.2-16-16c0-44.2 35.8-80 80-80 8.8 0 16 7.2 16 16s-7.2 16-16 16m0 384c-44.2 0-80-35.8-80-80v-16h160v16c0 44.2-35.8 80-80 80"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="vscentrum" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#status-of-gpu-computing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Supercomputers for Starters" class="md-header__button md-logo" aria-label="Supercomputers for Starters" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Supercomputers for Starters
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Status of GPU computing
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="vscentrum" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="custom"  aria-hidden="true"  type="radio" name="__palette" id="__palette_2">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Supercomputers for Starters" class="md-nav__button md-logo" aria-label="Supercomputers for Starters" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Supercomputers for Starters
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Table of contents
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C00_S00_preliminary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preliminary words
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C01_Introduction/C01_S01_Goals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Goals
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C01_Introduction/C01_S02_Why/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Why supercomputing?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C01_Introduction/C01_S03_What_it_is_not/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What it is not
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C01_Introduction/C01_S04_Compartmentalised/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A compartmentalised supercomputer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C01_Introduction/C01_S05_Overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview of the notes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C01_Introduction/C01_S06_Further_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Further reading
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Processors for supercomputers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Processors for supercomputers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S01_Intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S02_Basic_CPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A basic CPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S03_ILP_I_Pipelining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ILP I - Pipelining
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S04_ILP_II_Superscalar/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ILP II - Superscalar
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S05_Vectorisation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vector computing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S06_Shared_memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shared memory
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S07_Distributed_memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed memory
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S08_Modern_supercomputer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A modern (super)computer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S09_Node_architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Node architecture
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S10_Fast_evolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast (past) evolution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S11_Difference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An important difference...
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S12_Lessons_learnt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Processors: Lessons learnt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C02_Processors/C02_S13_Further_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Further reading on processors
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    The memory hierarchy
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            The memory hierarchy
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C03_Memory/C03_S01_Performance_gap/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The memory performance gap
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C03_Memory/C03_S02_Memory_pyramid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The memory pyramid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C03_Memory/C03_S03_AMD_Rome/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AMD Rome
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C03_Memory/C03_S04_AMD_Milan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AMD Milan
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Storing data on Supercomputers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Storing data on Supercomputers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C04_Storage/C04_S01_Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C04_Storage/C04_S02_Problems/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Problems
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C04_Storage/C04_S03_Parallel_filesystems/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel file systems
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C04_Storage/C04_S04_Revolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A storage revolution?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C04_Storage/C04_S05_To_remember/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    To remember
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C04_Storage/C04_S06_Further_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Further reading on storage
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Putting it all together
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Putting it all together
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S01_Scaling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scaling of technology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S02_Dennard_scaling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dennard scaling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S03_Cost_transistor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transistor cost
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S04_Keywords/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3 keywords
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S05_Andy_Bill/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Andy and Bill's law
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S06_Software_not_hardware/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software, not hardware
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C05_Summary1/C05_S07_Building_up_the_supercomputer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building up the supercomputer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Middleware
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Middleware
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C06_Middleware/C06_S01_Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Middleware: Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C06_Middleware/C06_S02_Shared_memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shared memory programming
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C06_Middleware/C06_S03_Vector_computing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vector programming
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C06_Middleware/C06_S04_Distributed_memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed memory programming
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C06_Middleware/C06_S05_Examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Middleware: Examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C06_Middleware/C06_S06_Further_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Further reading on middleware
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    What can we expect?
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            What can we expect?
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C07_Expectations/C07_S01_Speedup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speed-up
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C07_Expectations/C07_S02_Matrix_multiplication/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Matrix multiplication
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C07_Expectations/C07_S03_Scaling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speed-up and efficiency
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../C07_Expectations/C07_S04_Conclusions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" checked>
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Accelerators
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Accelerators
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../C08_S01_What_are_accelerators/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What are accelerators?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../C08_S02_Offloading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Offloading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../C08_S03_CPUs_accelerator_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPUs with accelerator features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../C08_S04_Programming_accelerators/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerator programming
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Status of GPU computing
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Status of GPU computing
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#too-much-hype" class="md-nav__link">
    <span class="md-ellipsis">
      Too much hype
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#problems-and-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      Problems and solutions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evolution-of-gpu-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Evolution of GPU nodes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evolution of GPU nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpu-subsystem-connected-via-pcie" class="md-nav__link">
    <span class="md-ellipsis">
      GPU subsystem connected via PCIe
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coherent-interconnect-between-cpu-and-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Coherent interconnect between CPU and GPU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#integration-of-cpu-and-gpu-in-a-single-package-nvidia-gh200" class="md-nav__link">
    <span class="md-ellipsis">
      Integration of CPU and GPU in a single package: NVIDIA GH200
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fully-unified-cpu-and-gpu-amd-mi300a" class="md-nav__link">
    <span class="md-ellipsis">
      Fully unified CPU and GPU: AMD MI300A
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../C08_S06_Further_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Further reading on accelerators
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../C09_Conclusions/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Conclusions
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Conclusions
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tags/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tags index
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#too-much-hype" class="md-nav__link">
    <span class="md-ellipsis">
      Too much hype
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#problems-and-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      Problems and solutions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evolution-of-gpu-nodes" class="md-nav__link">
    <span class="md-ellipsis">
      Evolution of GPU nodes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evolution of GPU nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpu-subsystem-connected-via-pcie" class="md-nav__link">
    <span class="md-ellipsis">
      GPU subsystem connected via PCIe
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coherent-interconnect-between-cpu-and-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Coherent interconnect between CPU and GPU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#integration-of-cpu-and-gpu-in-a-single-package-nvidia-gh200" class="md-nav__link">
    <span class="md-ellipsis">
      Integration of CPU and GPU in a single package: NVIDIA GH200
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fully-unified-cpu-and-gpu-amd-mi300a" class="md-nav__link">
    <span class="md-ellipsis">
      Fully unified CPU and GPU: AMD MI300A
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="status-of-gpu-computing">Status of GPU computing<a class="headerlink" href="#status-of-gpu-computing" title="Permanent link">&para;</a></h1>
<h2 id="too-much-hype">Too much hype<a class="headerlink" href="#too-much-hype" title="Permanent link">&para;</a></h2>
<p>Even though GPU computing, or accelerator computing in general, is definitely here to stay
and important for the future of not only supercomputing but computing in general as 
what can be done with a given amount of power is important in many markets
(also on mobiles that have to get their power from a battery), it does not mean that
it works for all applications.
Benchmarking of supercomputers with accelerators is often more benchmark<em>et</em>ing.
GPU computing is often overhyped using incomplete benchmarks (basically only benchmark
that part of the code that can be properly accelerated), marketing by numbers (redefine
common terms to get bigger numbers, something that in particular NVIDIA is very good
at) and comparing apples and oranges by comparing systems with a very different price
or total cost of ownership, e.g., comparing a server with multiple accelerators costing
60k EURO or more with a standard dual socket server costing only 10k EURO and using 
only one fifth of the power (these prices being what one actually paid for such nodes 
in 2022).</p>
<p>The NVIDIA vendor lock-in and its success in the market have made accelerators very 
expensive. At the current price point, GPU computing only makes sense from a price point
of view if the speed-up at the application level is a factor of 2.5 or more per accelerator card
compared to a standard medium-sized dual socket node. Due to the overdemand due to the
explosion of AI, the situation is currently getting even worse as the prices of GPU cards
rise faster than those of CPUs, so this may soon become a factor of 4 or 5 that you need to gain.</p>
<p>As we have seen, some features of accelerators have been carried over to traditional CPUs 
in the form of new instructions supporting vector and nowadays even matrix computing, and 
in some cases they may just be the better choice as CPUs have more memory readily available
and as programming is easier.</p>
<h2 id="problems-and-solutions">Problems and solutions<a class="headerlink" href="#problems-and-solutions" title="Permanent link">&para;</a></h2>
<p>There are several problems with current GPU designs:</p>
<ol>
<li>
<p>The amount of memory that a GPU can address directly and has fast enough access to,
    is limited. 2020 GPUs were limited to 32-48 GB of memory, in early 2021 a 80 GB GPU
    appeared on the market, in 2022, the first GPU with 128 GB of memory appeared
    on the market (AMD MI250/MI250X), 
    in (very) late 2023, the first GPUs with 192 GB of memory
    became available (AMD MI300X) and by the end of 2024 the first GPUs with
    256 GB of useable memory made their appearance (MI325X). 
    But this is still relatively small to typical memory sizes on a regular dual
    socket server that is much slower than the GPU.</p>
</li>
<li>
<p>Programming bottleneck: Having to organise all data transport manually and working with
    separate memory spaces is a pain.</p>
</li>
<li>
<p>The link between the CPU and the GPU is a bottleneck. The PCIe bus that typically links the CPU to the GPU has 
    a rather limited bandwidth compared to either the bandwidth of the CPU memory of the bandwidth
    of GPU memory. </p>
</li>
<li>
<p>The GPU is rather slow for serial code, so that code often has to run on the host.
    Which is then an issue since it may require additional copying between the CPU and GPU.</p>
</li>
</ol>
<p>However, there is hope.</p>
<p>The amount of memory that can be used by a GPU will increase a lot the coming years. Both the
memory packages are getting bigger by stacking more dies in 3D, and the number of memory packages
that can be integrated in the overall GPU package is increasing. 
In (very) late 2023, the first GPUs with 192 GB of memory appeared on the market, using
8 24 GB packages. It is expected that by 2025 the number of packages might grow to 12,
with 32 GB packages also becoming available, resulting in 384 GB of RAM.
(The current HBM standard, HBM3E, theoretically even allows 64 GB packages.)</p>
<p>The programming bottleneck can already be partially solved by unified memory, using memory pointers
that work on both CPU and GPU, and further hardware support for virtual memory that can then trigger
software that migrates memory pages under the hood. NVIDIA GPUs have had some of those features since
the Pascal generation in 2017. However, one can do even better by physically sharing memory spaces
between GPU and CPU, and supporting some level of coherency so that the CPU can access the GPU memory 
without risk of inconsistent data, or even the GPU can access the memory of the CPU, though that is less
interesting as the CPU can never provide the memory bandwidth that the GPU needs to perform well. 
NUMA style shared memory spaces were first explored in the Sierra and Summit USA pre-exascale
systems (as we discussed before) but is now also seen in the MI250X GPU from AMD which is a special 
version of the MI200 family connecting to the CPU through InfinityFabric, the same interconnect that AMD 
uses internally in its sockets to link the CPU dies to the I/O die, and also uses to connect CPU sockets
or to connect GPUs to each other in the MI100 and MI200 generations. 
The Intel Ponte Vecchio GPU combined with the Sapphire Rapids CPU that is used in the Aurora supercomputer
supports a similar feature, as does the NVIDIA Grace CPU and Hopper GPU integrated in a single package.</p>
<p>The physical sharing of memory spaces with some level of coherency is also the first step in solving
the problem of copying data back and forth all the time. E.g., if a CPU can access memory attached to the 
GPU without risks of coherency problems, then there is less need to copy full memory pages and also not to 
copy those back, as the link that is used in those GPU systems to connect the CPU to GPU is as fast as the
links that are typically used to connect two CPU sockets. The NVIDIA Grace Hopper "superchip" shows the next 
step. By integrating the CPU and GPU in the same package, it is possible to have a much higher bandwidth
between both, reducing the copying bottleneck in cases where copying is still needed. 
However, with the AMD MI300A, and without doubt future Intel and NVIDA chips, 
we will see even closer integration where CPU and GPU chiplets share the memory controllers.
The Apple M series chips give an indication of what can be obtained with such a system, as 
these systems perform way better in some applications that use acceleration than one would expect from
looking at systems with discrete GPUs with similar theoretical performance. This can solve both the 
third and fourth issue mentioned above.</p>
<h2 id="evolution-of-gpu-nodes">Evolution of GPU nodes<a class="headerlink" href="#evolution-of-gpu-nodes" title="Permanent link">&para;</a></h2>
<p>We will now discuss this evolution in some more detail.</p>
<h3 id="gpu-subsystem-connected-via-pcie">GPU subsystem connected via PCIe<a class="headerlink" href="#gpu-subsystem-connected-via-pcie" title="Permanent link">&para;</a></h3>
<p>Around 2016, a typical GPU compute node consisted of a dual socket server with 1-4 GPUs attached
to the CPUs. A typical design would have been:</p>
<p><img alt="2016 GPU design" src="../../img/C08_S05_01_2016_GPU.jpg" /></p>
<p>The red line between the two CPUs denotes a fully cache coherent link between the CPUs. 
In 2016 this would very likely have been either Intel CPUs or IBM POWER CPUs, and both
had proprietary fully cache coherent links to link CPUs (but not GPUs) in a shared memory system.
The red link between the GPUs denotes a similarly proprietary connection between the
GPUs for easy data transfer between the GPUs at typically a much higher bandwidth than
that offered by the connections between the CPU and GPU. However, not all systems used
such a link between graphics cards. A CPU was connected to the GPUs using PCIe, and
similarly a network interface would also be connected to a CPU using PCIe.</p>
<p>A typical 4-GPU node based on the NVIDIA Ampere A100 GPU launched
in 2020 would look similar to:</p>
<p><img alt="2020 NVIDIA A100" src="../../img/C08_S05_02_2020_A100.jpg" /></p>
<p>There are many variants of quad GPU designs with the A100 GPU, with single and dual
socket CPU servers. However, as some 2020-era CPUs didn't have enough PCIe lanes
to connect 4 GPUs, 2 network cards and in some cases also some local fast SSDs
on two sockets (let alone a single CPU socket),
a different solution was needed. 
The above design solves this by using two PCIe switches (the magenta
circles), and each PCIe switch connects the CPU to two of the GPUs. 
In the above design two network cards are used per node, one connected to
each of the CPU sockets. Some variants of the design will connect the network 
cards and/or NVMe SSDs (a type of SSD that uses the PCIe interface for fast data
transfer) also to the switches for better direct data transfer between 
the interconnect and the GPUs and/or the SSDs and the GPUs.</p>
<h3 id="coherent-interconnect-between-cpu-and-gpu">Coherent interconnect between CPU and GPU<a class="headerlink" href="#coherent-interconnect-between-cpu-and-gpu" title="Permanent link">&para;</a></h3>
<p>The next evolution of this design is used in the USA pre-exascale systems
Sierra and Summit, both using IBM POWER9 CPUs and NVIDIA Volta V100 GPUs.
More recently, the idea is revived in the 
GPU compute nodes of the Frontier
and LUMI supercomputers based on the MI250X GPU. A simplified diagram of the
LUMI and Frontier GPU nodes is:</p>
<p><img alt="A simplified MI250X node" src="../../img/C08_S05_03_MI250X.jpg" /></p>
<p>The GPU compute nodes of LUMI and Frontier use a special variant of the Zen3-based
AMD Epyc processor. In this variant, the PCIe lanes are replaced by Infinity Fabric
connections. In an MI250X, the 4 GPU packages are connected with each other and with 
the CPU through Infinity Fabric links. Each GPU package connects to its own quarter of
the AMD Epyc processor (remember from earlier that the I/O die is subdivided in 4
quarters, in this case each connected to two CPU chiplets with 8 cores each).
This creates a unified memory space with some level of coherency. 
Also noteworthy is that the
interconnect is no longer connected to the CPU, but the 4 network cards are each
connected to a GPU package (through a PCIe interface). This makes this compute
node really a GPU-first system, almost a system where the CPU is only used for
those parts of the code that cannot be accelerated at all by a GPU and to run the 
Linux operating system.</p>
<p>The true picture of the MI250X GPU node is a bit more complicated though. Each GPU package
contains two GPU dies, and these are connected to each other through some Infinity Fabric
links. Each GPU die connects to 4 memory packages, with 64 GB of memory per GPU die.
However, the connection between two GPU dies is sufficiently bandwidth-starved that
programming-wise a single GPU package should be considered as two separate GPUs. 
Each individual GPU die has its own InfinityFabric link to the CPU and seems to have a
preferential CPU chiplet. Even though the connection between the GPU packages appears to 
be an all-to-all connection, this is not true when one looks at the connections between
the GPU dies. </p>
<h3 id="integration-of-cpu-and-gpu-in-a-single-package-nvidia-gh200">Integration of CPU and GPU in a single package: NVIDIA GH200<a class="headerlink" href="#integration-of-cpu-and-gpu-in-a-single-package-nvidia-gh200" title="Permanent link">&para;</a></h3>
<p>Even though the MI250X has a level of cache coherency, using the memory in a unified matter
is still a problem, partly because of the extra latency introduced by the fairly long distance
between the CPU and GPU, partly also because of the limited memory bandwidth on the CPU side.
NVIDIA's Grace Hopper Superchip, available in 2024, works on those two problems by integrating
the CPU and GPU on a single package and not only putting the GPU memory, but also the
CPU memory on that package. 
The CPU part is called Grace and is a CPU based on the ARMv9 architecture, the newest
version of the ARM architecture at the time of design of the Grace processor.
The GPU part of the package is the Hopper architecture and similar to the one in the
SXM and PCIe cards released in the fall of 2022, but with all 6 memory controllers
enabled and faster HBM3e memory (also used in the regular H200 GPU).</p>
<p>The CPU and GPU still both have their own memory controllers and basically behave as
separate NUMA domains, but as the connection between the two has been brought on-chip
the bandwidth between CPU and GPU is a lot higher than in the MI250X architecture
or the Summit and Sierra systems with IBM POWER9 and NVIDIA V100 chips.
The CPU memory is not provided through external DIMMs, but through a number of internal
LPDDR5X modules (for a total of 480 GB) 
integrated in the CPU-GPU package in a similar way as the GPU memory has
been integrated in the package for a number of generations already. 
Integration of this memory type is popular in smartphones where it saves both space
and power, and is also used in the Apple Silicon M-series chips, where in addition to
space and power savings it also provides higher bandwidth. In the Grace chip it 
enables a very high memory bandwidth for the CPU, even 20% better than what the 
AMD EPYC 4 generation offers per socket (but not as much as the Intel Sapphire Rapids
MAX chips that incorporate a small amount of GPU-style memory in the package) while 
still offering a high memory capacity.</p>
<p>The Grace Hopper superchip provides two types of external connections. There are a number
of regular PCIe connections that come from the CPU die. They can be used to attach, e.g., network
cards (including a HPC interconnect) and NVMe drives.
There are also a number of NVLINK connections coming from the GPU die. These connections
are similar to the ones already used in previous generation NVIDIA GPUs to link GPU packages
and offer a much higher bandwidth interconnect. They can be used to interconnect a number
of Grace Hopper superchips in a NUMA shared memory way.</p>
<p>This makes the Grace Hopper superchip a very flexible building block.
Depending on the needs those chips can be combined in different ways. 
One can connect individual single package nodes through any HPC interconnect in a distributed
memory way. 
It is also possible to use NVLINK technology to connect multiple superchips into a single system
where each CPU and each GPU appears as a NUMA node to the OS. 
The bandwidth of this connection is much higher than the typical inter-socket interconnect in
CPU-based servers, but still a lot lower than the memory bandwidth that the GPU memory system can
offer. So it is very important that applications exploit the NUMA structure of the memory.
It is also possible to combine both approaches:
Build supercomputer nodes with up to 8 superchips with a single NVLINK switch level,
and link those nodes together using a traditional HPC interconnect. A possible layout of such a node 
is shown in the following figure:</p>
<p><img alt="A 4-GPU GH100 node" src="../../img/C08_S05_04_GH100.jpg" /></p>
<p>In this figure we combine 4 Grace Hopper packages in a single node and have chose to connect each
package directly to the interconnect for additional bandwidth.</p>
<h3 id="fully-unified-cpu-and-gpu-amd-mi300a">Fully unified CPU and GPU: AMD MI300A<a class="headerlink" href="#fully-unified-cpu-and-gpu-amd-mi300a" title="Permanent link">&para;</a></h3>
<p>The AMD MI250X was really just a transition to the MI300 "Antares" series, 
that in one variant goes one step further beyond the integration
that the NVIDIA Grace Hopper architecture offers. 
In that generation, announced in December 2023, 
one of the variants (the MI300A) merges the CPU and GPU completely,
as CPU cores and GPU Compute Units are integrated in a single package and share 
the memory controllers and on-package memory.
In fact, the reality is that
memory outside the package is also starting to limit CPU performance as an increasing number
of CPU codes becomes memory bandwidth bound, so even for the CPU it makes sense to switch
to smaller but much higher bandwidth memory in the package. </p>
<p>The AMD MI300A
fully integrates the CPU and GPU chiplets and memory controllers with memory in a single
package. 
Whereas the MI250x has some level of cache coherency but still needs to rely on page transfers in
most cases, in the MI300A the CPU and GPU memory
is fully unified (physical and virtual), with both sharing the same memory controllers and memory, which will enable
to fully eliminate redundant memory copies at least when going between CPU and GPU in the same package.
The MI300A was first mentioned at the AMD Financial Analyst Day in June 2022 and at 
<a href="https://youtu.be/OMxU4BDIm4M?t=5382">CES'2023 (early January 2023)</a>,
where a full package was shown, but still with very little detail.
It was launched in AMD's <a href="https://www.youtube.com/watch?v=tfSZqjxsr0M&amp;t=6051s">AI event on December 6, 2023</a>.
The <a href="https://www.amd.com/en/products/accelerators/instinct/mi300/mi300a.html">MI300A</a> 
combines 24 zen4 CPU cores with 228 CDNA3 GPU Compute Units in a single package.
The package contains 13 chiplets stacked into two layers. 
The bottom layer contains 4 chiplets with the memory controllers and 
last level cache. These 4 chiplets connect to 8 HBM3 memory modules 
offering a total of 128 GB of memory with a bandwidth of 5.3 TB/s.
On top of this are 6 GPU chiplets with 38 Compute Units each,
and 3 CPU chiplets with 8 zen4 cores each.
The bandwidth between these 13 chiplets is much higher than between the MI250X
chiplets, enabling the whole package to function as a single GPU.</p>
<p>The MI300A is used as the basis of the El Capitan exascale supercomputer
installed at Lawrence Livermore National Laboratory in the USA. 
The basic design of the node is shown in the following picture:</p>
<p><img alt="A MI300A supercomputer node" src="../../img/C08_S05_05_MI300.jpg" /></p>
<p>Here we see four MI300A packages. These four packages have an all-to-all connection using
a new generation of InfinityFabric, and each GPU packages also connects to a network card
using PCIe.</p>
<p>The total memory capacity of such a node is rather limited. 
It is not clear why AMD chose to use the 16 GB memory packages rather than the 
24 GB ones (which would have resulted in 192 GB of memory per package), 
as the latter are used in the MI300X which is the discrete, PCIe-attached
version of the MI300 GPUs. It may be for cost reasons, or simply because the
verification and production of MI300A started a few months before MI300X and the 24 GB
packages may not have been available yet.
But for applications that don't need those
large memory capacities and scale nicely over NUMA domains and then further over distributed memory
nodes, the more uniform architecture will certainly make life easier and offer great performance
benefits.</p>
<p>In Europe, HLRS has ordered a small system based on MI300A GPUs to prepare for a bigger
exascale system using a future AMD GPU later in the decade.</p>
<p>Intel was also working on a similar design, code-named Falcon Shores that was intended to hit
the market in 2024, but in an announcement in March 2023 it was said that the chip was postponed
till 2025 (but it did not show up), 
and the announcement also mentioned it as a GPU, explicitly scrapping the XPU term they
used before. Since then, Intel went silent and it is not even clear if they will launch another
datacenter-ready GPU for general compute and AI.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../C08_S04_Programming_accelerators/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Accelerator programming">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Accelerator programming
              </div>
            </div>
          </a>
        
        
          
          <a href="../C08_S06_Further_reading/" class="md-footer__link md-footer__link--next" aria-label="Next: Further reading on accelerators">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Further reading on accelerators
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/channel/UC3szWMS7glcfWsEZTZXQ1oQ" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.top", "navigation.indexes", "navigation.footer", "header.autohide", "toc.follow", "content.code.annotate", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.60a45f97.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>